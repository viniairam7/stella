const startBtn = document.getElementById("start-button");
const stopBtn = document.getElementById("stop-button"); // Este bot√£o n√£o est√° mais no HTML, mas a vari√°vel pode ser mantida ou removida se n√£o for usada em outro lugar.
const statusDiv = document.getElementById("status");
const starElement = document.getElementById("star");

// Novos elementos para os bot√µes do rodap√©
const attachPhotoButton = document.getElementById("attach-photo-button");
const endCallButton = document.getElementById("end-call-button");
const fileUpload = document.getElementById("file-upload"); // O input de arquivo escondido

let recognition;
const synth = window.speechSynthesis;
let selectedVoice = null;
let voicesLoaded = false;
let firstMicClick = true;

// Fun√ß√£o para carregar e selecionar a voz
function loadAndSelectVoice() {
  const voices = synth.getVoices();
  if (voices.length > 0) {
    console.log("Vozes dispon√≠veis:");
    voices.forEach((voice, index) => {
      console.log(`${index}: ${voice.name} (${voice.lang}) - Default: ${voice.default}`);
    });

    // Prioriza a voz "Alex" se dispon√≠vel (boa qualidade no iOS)
    selectedVoice = voices.find(voice => voice.name === "Alex" && voice.lang === 'en-US');

    // Se "Alex" n√£o for encontrada, tenta "Google US English" (boa no Chrome/Android)
    if (!selectedVoice) {
      selectedVoice = voices.find(v => v.name.includes("Google US English"));
    }

    // Se nenhuma das anteriores, tenta outras vozes femininas em ingl√™s
    if (!selectedVoice) {
      selectedVoice = voices.find(v => (v.name.includes("Samantha") || v.name.includes("Female")) && v.lang.startsWith('en'));
    }

    // Fallback para qualquer voz em ingl√™s
    if (!selectedVoice) {
        selectedVoice = voices.find(v => v.lang === 'en-US');
    }

    // √öltimo fallback para a primeira voz dispon√≠vel
    if (!selectedVoice) {
        selectedVoice = voices?.[0];
    }

    voicesLoaded = true;
    console.log("Voz selecionada:", selectedVoice ? selectedVoice.name : "Nenhuma voz preferida encontrada, usando fallback.");
  } else {
    console.warn("Nenhuma voz dispon√≠vel ainda. Tentando novamente...");
  }
}

// CR√çTICO PARA IOS: For√ßa o carregamento das vozes no primeiro toque do usu√°rio na p√°gina
window.addEventListener('click', () => {
  if (!voicesLoaded) {
    synth.getVoices();
    loadAndSelectVoice();
    console.log("Vozes carregadas ou tentativa de carregamento acionada por clique inicial na p√°gina.");
  }
}, { once: true });

// Tenta carregar as vozes quando elas mudam (pode n√£o disparar sem intera√ß√£o no iOS inicialmente)
window.speechSynthesis.onvoiceschanged = () => {
  if (!voicesLoaded) {
    loadAndSelectVoice();
  }
};

// Inicializa√ß√£o do webkitSpeechRecognition
if ('webkitSpeechRecognition' in window) {
  recognition = new webkitSpeechRecognition();
  recognition.lang = 'en-US';
  recognition.continuous = false;
  recognition.interimResults = false;

  recognition.onstart = () => {
    statusDiv.textContent = "‚ú® Stella is listening...";
    starElement.classList.add('speaking');
    console.log("Reconhecimento de voz iniciado.");
  };

  recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript;
    statusDiv.textContent = "üó£Ô∏è You said: " + transcript;
    starElement.classList.remove('speaking');
    console.log("Voc√™ disse:", transcript);
    sendToStella(transcript);
  };

  recognition.onerror = (event) => {
    statusDiv.textContent = "‚ùå Error: " + event.error + ". Please try again.";
    console.error("Speech Recognition Error:", event.error);
    starElement.classList.remove('speaking');
    if (event.error === 'not-allowed') {
      alert('Permiss√£o de microfone negada. Por favor, verifique as configura√ß√µes do seu navegador.');
    }
  };

  recognition.onend = () => {
    statusDiv.textContent = "‚èπÔ∏è Wait the aswer. Touch again to talk!";
    starElement.classList.remove('speaking');
    console.log("Reconhecimento de voz encerrado.");
  };
} else {
  statusDiv.textContent = "‚ùå Speech recognition is not supported in this browser.";
  alert("Speech recognition is not supported in this browser. Please use Chrome on Android/Desktop or Safari on iOS.");
}

// Evento de clique do bot√£o de iniciar (microfone)
startBtn.onclick = () => {
  console.log("Bot√£o de microfone clicado.");

  if (!voicesLoaded) {
      loadAndSelectVoice();
      if (!selectedVoice) {
          statusDiv.textContent = "Please wait, loading Stella's voice...";
          console.warn("Voz ainda n√£o carregada.");
          if (recognition) {
              try {
                  recognition.start();
              } catch (e) {
                  console.error("Erro ao tentar iniciar o reconhecimento de voz:", e);
                  statusDiv.textContent = "‚ùå Error starting microphone. Check permissions.";
              }
          }
          return;
      }
  }

  if (firstMicClick && selectedVoice) {
      speak("Hello! How can I help you?");
      firstMicClick = false;
      setTimeout(() => {
          if (recognition) {
              try {
                  recognition.start();
              } catch (e) {
                  console.error("Erro ao tentar iniciar o reconhecimento de voz (ap√≥s 'Hello'):", e);
                  statusDiv.textContent = "‚ùå Error starting microphone. Check permissions.";
              }
          }
      }, 1000);
  } else {
      if (recognition) {
          try {
              recognition.start();
          } catch (e) {
              console.error("Erro ao tentar iniciar o reconhecimento de voz (subsequente):", e);
              statusDiv.textContent = "‚ùå Error starting microphone. Check permissions.";
          }
      } else {
        statusDiv.textContent = "Speech recognition is not initialized.";
      }
  }
};

// Evento de clique do bot√£o de parar (stopBtn n√£o est√° mais no HTML, mas a fun√ß√£o speak ainda usa synth.cancel)
// Se voc√™ quiser um bot√£o de pausa real, precisaria reintroduzi-lo no HTML.
// Por enquanto, o bot√£o 'X' (endCallButton) pode ser usado para parar a sess√£o.

// Evento de clique do bot√£o de encerrar (X)
endCallButton.onclick = () => {
  console.log("Bot√£o de encerrar clicado.");
  if (recognition) {
    recognition.stop(); // Para o reconhecimento de voz
  }
  synth.cancel(); // Para qualquer fala em andamento
  statusDiv.textContent = "Session ended. Touch to talk!";
  starElement.classList.remove('speaking'); // Garante que a anima√ß√£o pare
  firstMicClick = true; // Opcional: Reseta para que "Hello!" seja dito novamente na pr√≥xima sess√£o
  // Voc√™ pode adicionar aqui qualquer outra l√≥gica para "encerrar a chamada"
};


// Fun√ß√£o para a Stella falar
function speak(textToSpeak) {
  if (!textToSpeak) {
    console.warn("Nenhum texto para falar.");
    return;
  }
  if (!selectedVoice) {
    console.warn("Voz n√£o selecionada para falar. Tentando carregar novamente.");
    loadAndSelectVoice();
    statusDiv.textContent = "Loading voice, please try again soon.";
    return;
  }

  const utter = new SpeechSynthesisUtterance(textToSpeak);
  utter.lang = 'en-US';
  utter.voice = selectedVoice;

  utter.onstart = () => {
      starElement.classList.add('speaking');
      console.log("Stella come√ßou a falar.");
  };

  utter.onend = () => {
      starElement.classList.remove('speaking');
      console.log("Stella terminou de falar.");
  };

  utter.onerror = (event) => {
      console.error("Speech Synthesis Error:", event.error);
      starElement.classList.remove('speaking');
      statusDiv.textContent = "‚ùå Stella couldn't speak. Error: " + event.error;
  };

  synth.cancel();
  try {
      synth.speak(utter);
  } catch (e) {
      console.error("Erro ao tentar iniciar a s√≠ntese de fala:", e);
      statusDiv.textContent = "‚ùå Stella couldn't speak. Please try again.";
  }
}

// Fun√ß√£o para enviar a pergunta para o backend da Stella (OpenRouter API)
function sendToStella(pergunta) {
  statusDiv.textContent = "‚ú® Stella is thinking...";
  fetch("https://stella-7.onrender.com/perguntar", {
    method: "POST",
    headers: {
      "Content-Type": "application/json"
    },
    body: JSON.stringify({ pergunta })
  })
  .then(res => {
    if (!res.ok) {
        return res.json().then(errorData => {
            throw new Error(errorData.error || `HTTP error! status: ${res.status}`);
        });
    }
    return res.json();
  })
  .then(data => {
    const resposta = data.reply || "Sorry, I didn‚Äôt understand.";
    statusDiv.textContent = "‚ú® Stella: " + resposta;
    speak(resposta);
  })
  .catch(err => {
    console.error("Erro ao contatar Stella backend:", err);
    statusDiv.textContent = "‚ùå Error contacting Stella: " + err.message;
    speak("I'm sorry, I couldn't connect to my brain at the moment. Please try again.");
  });
}

// L√≥gica para o bot√£o de anexar foto para tradu√ß√£o
attachPhotoButton.onclick = () => {
  fileUpload.click(); // Simula um clique no input de arquivo escondido
};

fileUpload.onchange = () => {
  const file = fileUpload.files?.[0];
  if (file) {
    if (!file.type.startsWith('image/')) {
      statusDiv.textContent = "üö´ Por favor, selecione um arquivo de imagem.";
      alert("Por favor, selecione um arquivo de imagem (JPEG, PNG, GIF, etc.).");
      return;
    }

    statusDiv.textContent = "‚è≥ Carregando imagem para tradu√ß√£o...";
    const reader = new FileReader();
    reader.onload = function(event) {
      const imageDataUrl = event.target?.result; // Conte√∫do da imagem em Base64
      if (imageDataUrl) {
        // Envie o Base64 da imagem para o seu backend
        sendImageForTranslation(imageDataUrl, file.name);
      } else {
        statusDiv.textContent = "‚ùå Falha ao ler a imagem.";
      }
    };
    reader.onerror = function() {
      statusDiv.textContent = "‚ùå Erro ao ler a imagem.";
    };
    reader.readAsDataURL(file); // L√™ o arquivo como Data URL (Base64)
  } else {
    statusDiv.textContent = "üö´ Nenhuma imagem selecionada.";
  }
};

function sendImageForTranslation(imageDataUrl, fileName) {
  statusDiv.textContent = "üì° Enviando imagem para tradu√ß√£o...";
  // IMPORTANTE: Substitua 'YOUR_BACKEND_TRANSLATION_ENDPOINT' pela URL real do seu backend
  // que ir√° processar a imagem e envi√°-la para um servi√ßo de tradu√ß√£o de imagem/OCR.
  fetch("YOUR_BACKEND_TRANSLATION_ENDPOINT", {
    method: "POST",
    headers: {
      "Content-Type": "application/json"
    },
    body: JSON.stringify({ imageData: imageDataUrl, name: fileName })
  })
  .then(res => {
    if (!res.ok) {
        return res.json().then(errorData => {
            throw new Error(errorData.error || `HTTP error! status: ${res.status}`);
        });
    }
    return res.json();
  })
  .then(data => {
    const translationResult = data.translationResult || "No translation found.";
    statusDiv.textContent = "‚úÖ Tradu√ß√£o conclu√≠da: " + translationResult;
    speak(translationResult); // Stella pode falar a tradu√ß√£o
  })
  .catch(err => {
    console.error("Erro ao enviar imagem para tradu√ß√£o:", err);
    statusDiv.textContent = "‚ùå Erro ao traduzir imagem: " + err.message;
    speak("I'm sorry, I couldn't translate the image at the moment.");
  });
}

// Inicializa o carregamento da voz ao carregar a p√°gina
loadAndSelectVoice();
